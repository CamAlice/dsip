{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in Practice 2020\n",
    "\n",
    "*MGT-415*\n",
    "\n",
    "Ref : [https://www.kaggle.com/cgueret/covid-19-risk-factor-predictor/output](https://www.kaggle.com/cgueret/covid-19-risk-factor-predictor/output)\n",
    "\n",
    "## Project\n",
    "\n",
    "### Descriptive report\n",
    "\n",
    "Authors :\n",
    "- Rayan Chaouche\n",
    "- Yann Martinson\n",
    "- Christopher Padovani\n",
    "- Jules Triomphe\n",
    "\n",
    "### 1. Initialization\n",
    "\n",
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from ipyparallel import Client\n",
    "from ipyparallel.joblib import IPythonParallelBackend\n",
    "from joblib import Parallel, parallel_backend, register_parallel_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare parallel kernel\n",
    "\n",
    "*Install [here](https://ipyparallel.readthedocs.io/en/latest/), define the number of engines and click '**Start**' in the* **iPython Clusters** *tab.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile: default\n",
      "IDs: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "c = Client(profile='default')\n",
    "print('profile:', c.profile)\n",
    "print(\"IDs:\", c.ids) # Process id numbers\n",
    "bview = c.load_balanced_view()\n",
    "register_parallel_backend('ipyparallel',\n",
    "                          lambda : IPythonParallelBackend(view=bview))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**THE FOLLOWING CODE IS ADAPTED FROM [https://www.kaggle.com/cgueret/covid-19-risk-factor-predictor](https://www.kaggle.com/cgueret/covid-19-risk-factor-predictor)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load disease list\n",
    "\n",
    "- `efo_id` is the disease code from the *Experimental Factor Ontology (EFO)* and *MONDO* ontologies.\n",
    "- `disease_full_name` is the full name of the disease.\n",
    "- `number_of_associations` is the number of [associations](https://docs.targetvalidation.org/getting-started/getting-started/associated-targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>efo_id</th>\n",
       "      <th>disease_full_name</th>\n",
       "      <th>number_of_associations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFO_1000984</td>\n",
       "      <td>inflammatory breast carcinoma</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MONDO_0004093</td>\n",
       "      <td>esophageal basaloid carcinoma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EFO_0006352</td>\n",
       "      <td>laryngeal squamous cell carcinoma</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EFO_1000514</td>\n",
       "      <td>Salivary Gland Adenosquamous Carcinoma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EFO_1001965</td>\n",
       "      <td>pharyngeal squamous cell carcinoma</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          efo_id                       disease_full_name  \\\n",
       "0    EFO_1000984           inflammatory breast carcinoma   \n",
       "1  MONDO_0004093           esophageal basaloid carcinoma   \n",
       "2    EFO_0006352       laryngeal squamous cell carcinoma   \n",
       "3    EFO_1000514  Salivary Gland Adenosquamous Carcinoma   \n",
       "4    EFO_1001965      pharyngeal squamous cell carcinoma   \n",
       "\n",
       "   number_of_associations  \n",
       "0                     174  \n",
       "1                       1  \n",
       "2                     796  \n",
       "3                       0  \n",
       "4                     428  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_list = pd.read_csv('https://storage.googleapis.com/open-targets-data-releases/20.02/output/20.02_disease_list.csv.gz',\n",
    "                           compression='gzip')\n",
    "disease_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that there are no duplicate diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative regulation of circadian sleep/wake cycle, REM sleep                           1\n",
       "respiratory aspiration                                                                 1\n",
       "Corneoiridogoniodysgenesis                                                             1\n",
       "Timothy syndrome                                                                       1\n",
       "Steatocystoma multiplex - natal teeth                                                  1\n",
       "                                                                                      ..\n",
       "anti-citrullinated protein antibody seropositivity                                     1\n",
       "malignant renal pelvis neoplasm                                                        1\n",
       "Pfeiffer syndrome type 1                                                               1\n",
       "Autosomal dominant disease with diffuse palmoplantar keratoderma as a major feature    1\n",
       "porphyrin metabolism disease                                                           1\n",
       "Name: disease_full_name, Length: 16048, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_list.disease_full_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Kaggle data\n",
    "\n",
    "- `subject` is the paper id.\n",
    "- `predicate` is the relation to the disease.\n",
    "- `object` is the disease id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>327834</td>\n",
       "      <td>327834</td>\n",
       "      <td>327834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20831</td>\n",
       "      <td>6</td>\n",
       "      <td>9577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ENSG00000141510</td>\n",
       "      <td>isAssociatedTo</td>\n",
       "      <td>EFO_0000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1041</td>\n",
       "      <td>176088</td>\n",
       "      <td>7918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                subject       predicate       object\n",
       "count            327834          327834       327834\n",
       "unique            20831               6         9577\n",
       "top     ENSG00000141510  isAssociatedTo  EFO_0000618\n",
       "freq               1041          176088         7918"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_kaggle_data = pd.read_csv('COVID_KG_sample.csv')\n",
    "raw_kaggle_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject', 'predicate', 'object'], dtype='object')\n",
      "isAssociatedTo              176088\n",
      "hasGeneticClue              103103\n",
      "belongsToTherapeuticArea     22142\n",
      "isASpecific                  17548\n",
      "isAboutDisease                5986\n",
      "isAboutTarget                 2967\n",
      "Name: predicate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(raw_kaggle_data.columns)\n",
    "\n",
    "print(raw_kaggle_data.predicate.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the training, testing and validation sets\n",
    "\n",
    "We will validate our model by using the `hasGeneticClue` predicate. Therefore, all other predicates are moved to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "train_set = raw_kaggle_data[raw_kaggle_data['predicate']!='hasGeneticClue'].values\n",
    "print(type(train_set))\n",
    "genetic_clue_triples = raw_kaggle_data[raw_kaggle_data['predicate']=='hasGeneticClue']\n",
    "print(type(genetic_clue_triples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, we have the following definitions for each predicate :\n",
    "- `isAboutGene` connects a CORDI-19 paper to a target gene.\n",
    "- `isAboutDisease` connects a CORDI-19 paper to a Disease (i.e. a characteristic, condition, or behaviour - following OpenTargets terminology).\n",
    "- `isASsociatedTo` connects a target gene to a Disease (i.e. a characteristic, condition, or behaviour - following OpenTargets terminology).\n",
    "- `belongsToTherapeuticArea` associates a Disease to its therapeutic area, as provided by Open Targets.\n",
    "- `isASpecific` this predicate associates a Disease to an higher-up element in the Open Targets hierarchy (ontological path connecting higher classes of diseases to more specific instances).\n",
    "- `hasGeneticClue` this predicate connects a Disease to a characteristic, condition, or behaviour if there are genetic evidences that such connection exists.\n",
    "\n",
    "Hence, only `isAboutDisease` and `isASsociatedTo` are associated to a disease. Hence, we can build the used disease list from these two predicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_set_diseases =  np.unique(np.concatenate([\n",
    "    np.unique(train_set[train_set[:, 1] == 'isAboutDisease'][:, 2]),\n",
    "    np.unique(train_set[train_set[:, 1] == 'isAssociatedTo'][:, 2]),\n",
    "], 0))\n",
    "print('There are %s diseases in the training set.' %(len(train_set_diseases)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take 5% of these diseases to validate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_set_diseases = np.random.choice(list(train_set_diseases), 255).tolist()\n",
    "test_set = genetic_clue_triples[genetic_clue_triples[\"subject\"].isin(test_set_diseases)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove these from the training set and randomize the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_genetic_clue_triples = genetic_clue_triples[~genetic_clue_triples[\"subject\"].isin(test_set_diseases)]\n",
    "train_set = np.concatenate([train_set, train_genetic_clue_triples], 0)\n",
    "train_set = np.random.permutation(train_set)\n",
    "train_set_diseases =  np.unique(np.concatenate([\n",
    "    np.unique(train_set[train_set[:, 1] == 'isAboutDisease'][:, 2]),\n",
    "    np.unique(train_set[train_set[:, 1] == 'isAssociatedTo'][:, 2]),\n",
    "    np.unique(train_set[train_set[:, 1]=='hasGeneticClue'][:, 0]),\n",
    "    np.unique(train_set[train_set[:, 1]=='hasGeneticClue'][:, 2]),\n",
    "], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print('There are %s elements in the training set.' %(len(train_set)))\n",
    "print(train_set.view())\n",
    "print(type(train_set))\n",
    "print(test_set_diseases)\n",
    "print(type(test_set_diseases))\n",
    "print('There are %s elements in the testing set.' %(len(test_set)))\n",
    "print('There are %s elements in the raw data set.' %(len(raw_kaggle_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UP TO THIS POINT, THE CODE WAS ADAPTED FROM [https://www.kaggle.com/cgueret/covid-19-risk-factor-predictor](https://www.kaggle.com/cgueret/covid-19-risk-factor-predictor)**\n",
    "\n",
    "**WHAT COMES NEXT IS OUR OWN WORK PRODUCT**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>103103</td>\n",
       "      <td>103103</td>\n",
       "      <td>103103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2231</td>\n",
       "      <td>1</td>\n",
       "      <td>5160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>EFO_0000558</td>\n",
       "      <td>hasGeneticClue</td>\n",
       "      <td>Orphanet_70589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>687</td>\n",
       "      <td>103103</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject       predicate          object\n",
       "count        103103          103103          103103\n",
       "unique         2231               1            5160\n",
       "top     EFO_0000558  hasGeneticClue  Orphanet_70589\n",
       "freq            687          103103             552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_clue_triples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_pre_process():\n",
    "    \n",
    "    df_raw = genetic_clue_triples.copy()\n",
    "    \n",
    "    # output into dummies\n",
    "\n",
    "    dummy_dict = { key : ('1' if value == 'MONDO_0100096' else '0')\n",
    "              for key, value\n",
    "              in zip(df_raw['object'].values, df_raw['object'].values)}\n",
    "    df_raw.object.replace(dummy_dict, inplace = True)\n",
    "    df_raw.rename(columns = {'object' : 'covid'}, inplace = True)\n",
    "    \n",
    "    # X y splitting\n",
    "    \n",
    "    y = df_raw.covid.copy()\n",
    "    X_raw = df_raw.drop(columns = ['covid','predicate']).copy()\n",
    "    \n",
    "    # input into dummies\n",
    "    \n",
    "    X_raw_types = dict(X_raw.dtypes)\n",
    "    features = list(X_raw.columns)\n",
    "    categorical_features = [feat for feat in features if X_raw_types[feat] == 'O']\n",
    "    \n",
    "    X = pd.get_dummies(X_raw, columns = categorical_features,prefix_sep=':')\n",
    "    \n",
    "    return df_raw, categorical_features, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preprocessing_knn() :\n",
    "\n",
    "    df_raw, categorical_features, X, y = df_pre_process()\n",
    "    \n",
    "    # train val splitting\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "    y_train = y_train.tolist()\n",
    "    y_test = y_test.tolist()\n",
    "\n",
    "    return df_raw, categorical_features, X, X_train, X_test, y, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preprocessing_rf(test_size) :\n",
    "    \n",
    "    df_raw, categorical_features, X, y = df_pre_process()\n",
    "    \n",
    "    # train val splitting\n",
    "\n",
    "    train = np.random.rand(len(df_raw))> test_size\n",
    "\n",
    "    X_train = X[train]\n",
    "    X_test = X[~train]\n",
    "\n",
    "    y_train = y[train].tolist()\n",
    "    y_test = y[~train].tolist()\n",
    "\n",
    "    return df_raw, categorical_features, X, X_train, X_test, y, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(feature_importance_sorted, n, type_of_search):\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    x = np.arange(n)\n",
    "    y = [feature_importance_sorted[i][1] for i in range(n)]\n",
    "    labels = [feature_importance_sorted[i][0] for i in range(n)]\n",
    "    ax = sns.barplot(y,x,orient=\"h\");\n",
    "    plt.xlabel(\"Importance fraction\", fontsize = 12)\n",
    "    ax.set_xticklabels(['{:,.0%}'.format(x) for x in ax.get_xticks()])\n",
    "    plt.yticks(x,labels, fontsize = 15)\n",
    "    plt.title('Most important feature: {}'.format(type_of_search), fontsize = 15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw, categorical_features, X, X_train, X_test, y, y_train, y_test = df_preprocessing_knn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run simulations for k-values between 1 and 100 to find the best fit parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_uni = np.array([0])\n",
    "error_dist = np.array([0])\n",
    "\n",
    "for i in range(1, 100):\n",
    "    knn_uni = KNeighborsClassifier(n_neighbors=i, weights='uniform', n_jobs=-1)\n",
    "    knn_uni.fit(X_train, y_train)\n",
    "    pred_i_uni = knn_uni.predict(X_test)\n",
    "    error_uni = np.append(error_uni, np.array(np.mean(pred_i_uni != y_test)))\n",
    "\n",
    "    knn_dist = KNeighborsClassifier(n_neighbors=i, weights='distance', n_jobs=-1)\n",
    "    knn_dist.fit(X_train, y_train)\n",
    "    pred_i_dist = knn_dist.predict(X_test)\n",
    "    error_dist = np.append(error_dist, np.array(np.mean(pred_i_dist != y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(error_uni[1:], color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10, label='Uniform weights')\n",
    "plt.plot(error_dist[1:], color='black', linestyle='dashed', marker='o', markerfacecolor='green', markersize=10, label='Distance weights')\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "print('Minimum error rate with uniform weights: {:.2%} for k = {}'.format(min(error_uni[1:]), np.argmin(error_uni[1:]) + 1))\n",
    "print('Minimum error rate with distance weights: {:.2%} for k = {}'.format(min(error_dist[1:]), np.argmin(error_dist[1:]) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_uni = KNeighborsClassifier(n_neighbors = (np.argmin(error_uni[1:]) + 1), weights='uniform')\n",
    "classifier_uni.fit(X_train, y_train)\n",
    "classifier_dist = KNeighborsClassifier(n_neighbors = (np.argmin(error_dist[1:]) + 1), weights='distance')\n",
    "classifier_dist.fit(X_train, y_train)\n",
    "\n",
    "y_pred_uni = classifier_uni.predict(X_test)\n",
    "y_pred_dist = classifier_dist.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_uni), annot=True, fmt=\"d\", cmap=\"nipy_spectral\")\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title('Confusion matrix for the uniform weights KNN method (k = {})'.format(np.argmin(error_uni[1:]) + 1), fontsize = 15);\n",
    "print(\"UNIFORM WEIGHTS\")\n",
    "print(\"Accuracy: {:.2%}\".format(accuracy_score(y_test, y_pred_uni)))\n",
    "print(classification_report(y_test, y_pred_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_dist), annot=True, fmt=\"d\", cmap=\"nipy_spectral\")\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title('Confusion matrix for the distance weights KNN method (k = {})'.format(np.argmin(error_dist[1:]) + 1), fontsize = 15);\n",
    "print(\"DISTANCE WEIGHTS\")\n",
    "print(\"Accuracy: {:.2%}\".format(accuracy_score(y_test, y_pred_dist)))\n",
    "print(classification_report(y_test, y_pred_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier\n",
    "\n",
    "We will compare two methods, which are grid search and random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw, categorical_features, X, X_train, X_test, y, y_train, y_test = df_preprocessing_rf(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Grid search\n",
    "\n",
    "To avoid having too high a computational time, we will focus on 2 of the mot important parameters that are max depth and the number of estimators.\n",
    "\n",
    "##### Max Depth\n",
    "\n",
    "This parameter is the depth of the trees, which is one of the most important. We range it between 4 (anything lower seems too low and increases computational time without much results) and 15.\n",
    "\n",
    "##### Number of estimators\n",
    "\n",
    "This parameter is the number of trees that are going to be generated. Here the choice of the number of trees will mostly affect the computational time. Let's set the values between 10 and 500 and see the effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = list(range(4,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 15, 20, 50, 100, 200, 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the default 5 folds of cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth' : max_depth, 'n_estimators' : n_estimators }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, param_grid = grid_parameters, return_train_score=True, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72222, 2231)\n",
      "72222\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend IPythonParallelBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 11.8min\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    grid_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which model is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_score = grid_clf.best_score_\n",
    "grid_best_parameters = grid_clf.best_params_\n",
    "grid_best_max_depth = grid_best_parameters.get('max_depth')\n",
    "grid_best_n_estimators = grid_best_parameters.get('n_estimators')\n",
    "\n",
    "print('Grid search best_score: {:.5}'.format(grid_best_score))\n",
    "print('best_max_depth: {}'.format(grid_best_max_depth))\n",
    "print('best_n_estimators: {}'.format(grid_best_n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf_best = RandomForestClassifier(n_jobs = -1,max_depth = grid_best_max_depth, n_estimators = grid_best_n_estimators )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf_best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply it to our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_y_pred = grid_clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2%}\".format(accuracy_score(y_test, grid_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this accuracy, we can take a deeper look into the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cm = confusion_matrix(y_test, grid_y_pred)\n",
    "index = ['Negative','Positive']  \n",
    "columns = ['Negative','Positive']  \n",
    "cm_df = pd.DataFrame(grid_cm,columns,index) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"nipy_spectral\")\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title('Confusion matrix for the grid search', fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_feature_importances = [(list(X.columns)[i], grid_clf_best.feature_importances_[i]) for i in range(len(list(X.columns)))]\n",
    "grid_feature_importances.sort(key=itemgetter(1), reverse = True)\n",
    "plot_importance(grid_feature_importances, 10, 'Grid search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,grid_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection\n",
    "\n",
    "Let's try to run the model again, but this time selecting only the most impacting features to save us some work and let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_selected_features = [grid_feature_importances[i][0] for i in range(15)]\n",
    "grid_X_train_sel = X_train[grid_selected_features]\n",
    "grid_X_test_sel = X_test[grid_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    grid_clf.fit(grid_X_train_sel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_score_sel = grid_clf.best_score_\n",
    "grid_best_parameters_sel = grid_clf.best_params_\n",
    "grid_best_max_depth_sel = grid_best_parameters.get('max_depth')\n",
    "grid_best_n_estimators_sel = grid_best_parameters.get('n_estimators')\n",
    "print('Grid search best_score with selected features: {:.5}'.format(grid_best_score_sel))\n",
    "print('Grid search best_max_depth with selected features: {}'.format(grid_best_max_depth_sel))\n",
    "print('Grid search best_n_estimators with selected features: {}'.format(grid_best_n_estimators_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf_best_sel = RandomForestClassifier(n_jobs = -1,max_depth = grid_best_max_depth_sel, n_estimators = grid_best_n_estimators_sel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf_best_sel.fit(grid_X_train_sel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_y_pred_sel = grid_clf_best_sel.predict(grid_X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2%}\".format(accuracy_score(y_test, grid_y_pred_sel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Random Search\n",
    "\n",
    "After having explored a grid search, we can adopt another approach. Instead of searching for each value, let's give our model more parameters input, but instead let it choose randomly at each iteration one value for each parameter. It will then be evaluated again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = range(10,1000,50)\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "bootstrap = [True,False]\n",
    "max_depth = range(5,50,10)\n",
    "min_samples_leaf = range(2,100, 2)\n",
    "min_samples_split = range(2,100,2)\n",
    "\n",
    "random_parameters = {'n_estimators':n_estimators, 'max_features':max_features, 'max_depth':max_depth, 'min_samples_leaf':\n",
    "              min_samples_leaf}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf = RandomizedSearchCV(clf, param_distributions = random_parameters, n_iter = 20, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with parallel_backend('ipyparallel'):\n",
    "    random_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_score = random_clf.best_score_\n",
    "print('Random search best_score: {:.4}'.format(random_best_score))\n",
    "random_best_parameters = random_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf_best = RandomForestClassifier(max_depth = 35, max_features = 'sqrt', min_samples_leaf = 9, n_estimators = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf_best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_y_pred = random_clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cm = confusion_matrix(y_test, random_y_pred)\n",
    "annot_kws = {\"ha\": 'center',\"va\": 'center'}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"nipy_spectral\")\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_feature_importances = [(list(X.columns)[i], random_clf_best.feature_importances_[i]) for i in range(len(list(X.columns)))]\n",
    "random_feature_importances.sort(key=itemgetter(1), reverse = True)\n",
    "plot_importance(random_feature_importances, 10, 'Ransom search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,random_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.2%}\".format(accuracy_score(y_test, random_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Comparison\n",
    "\n",
    "##### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_grid, tpr_grid, _ = roc_curve(y_test, grid_y_pred)\n",
    "fpr_grid_sel, tpr_grid_sel, _ = roc_curve(y_test, grid_y_pred_sel)\n",
    "fpr_random, tpr_random, _ = roc_curve(y_test, random_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_grid, tpr_grid, label='Grid Search')\n",
    "plt.plot(fpr_grid_sel, tpr_grid_sel, label='Grid Search with Selected Predictors')\n",
    "plt.plot(fpr_random, tpr_random, label='Random Search')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "roc_auc_grid = roc_auc_score(y_test, grid_y_pred)\n",
    "print('ROC AUC for Grid Search: %.5f' % roc_auc_grid)\n",
    "roc_auc_grid_sel = roc_auc_score(y_test, grid_y_pred_sel)\n",
    "print('ROC AUC for Grid Search with selected predictors: %.5f' % roc_auc_grid_sel)\n",
    "roc_auc_random = roc_auc_score(y_test, random_y_pred)\n",
    "print('ROC AUC for Random Search: %.5f' % roc_auc_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that all three methods are better than a random prediction. The Grid Search with Selected Predictors has slightly better prediction than the Random Search, which has in turn slightly better prediction than the basic Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0.05, 0.15)\n",
    "plt.ylim(0.4, 0.55)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_grid, tpr_grid, label='Grid Search')\n",
    "plt.plot(fpr_grid_sel, tpr_grid_sel, label='Grid Search with Selected Predictors')\n",
    "plt.plot(fpr_random, tpr_random, label='Random Search')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision - Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_precision, grid_recall, _ = precision_recall_curve(y_test, grid_y_pred)\n",
    "grid_precision_sel, grid_recall_sel, _ = precision_recall_curve(y_test, grid_y_pred_sel)\n",
    "random_precision, random_recall, _ = precision_recall_curve(y_test, random_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "no_skill = len(y_test[y_test == 1]) / len(y_test)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(grid_recall, grid_precision, marker='.', label='Grid Search')\n",
    "plt.plot(grid_recall_sel, grid_precision_sel, marker='.', label='Grid Search')\n",
    "plt.plot(random_recall, random_precision, marker='.', label='Random Search')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "pr_auc_grid = auc(grid_recall, grid_precision)\n",
    "print('Precision-Recall AUC for Grid Search: %.5f' % pr_auc_grid)\n",
    "pr_auc_grid_sel = auc(grid_recall_sel, grid_precision_sel)\n",
    "print('Precision-Recall AUC for Grid Search with selected predictors: %.5f' % pr_auc_grid_sel)\n",
    "pr_auc_random = auc(random_recall, random_precision)\n",
    "print('Precision-Recall AUC for Random Search: %.5f' % pr_auc_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
